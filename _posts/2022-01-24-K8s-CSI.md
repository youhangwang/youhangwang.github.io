---
title: Container Storage Interface（CSI) In Kubernetes
tags: ContainerStorage Kubernetes CSI 
--- 

[CSI](../../../2021/10/29/CSI.html)是一套通用的RPC接口，可以将Block和File System暴露给Kubernetes等容器编排系统(CO)上运行的容器化工作负载。通过使用CSI，第三方存储提供商可以编写和部署插件，在Kubernetes中公开新的存储系统，而无需接触Kubernetes的核心代码。
<!--more-->


## Development And Deployment

[container-storage-interface-drivers-announce](https://groups.google.com/forum/#!forum/container-storage-interface-drivers-announce)会发布可能影响现有CSI Driver实现的CSI或Kubernetes的更改。

Kubernetes没有具体规定如何打包和部署CSI Driver，但是对Kubernetes（Master和Node）组件如何找到CSI Driver并与之通信规定了以下内容：

- Kubelet与CSI Driver的通信:
  - Kubelet通过插件注册机制发现 CSI Driver。 
  - Kubelet通过Unix Domain Socket直接向CSI Driver发出调用（如 NodeStageVolume、NodePublishVolume 等）以挂载和卸载卷。

- Master与CSI Driver的通信:
  - Kubernetes Master组件不与CSI Driver直接通信（例如通过 Unix Domain Socket或其他方式）。
  - Kubernetes Master组件仅与Kubernetes API交互。
  - 因此，基于Kubernetes API的操作（如卷创建、卷附加、卷快照等）的CSI Driver必须WatchKubernetes API并调用适当的CSI接口。

这些要求是最低限度的规定，CSI Driver开发人员可以自由地实施和部署他们认为合适的Driver。但是为了简化开发和部署，推荐使用以下组件开发CSI Driver：
- Kubernetes CSI Sidecar Container
- Kubernetes CSI Object
- CSI Driver测试工具

要使用此机制实现CSI Driver，CSI Driver开发人员应该：
1. 创建一个容器化应用程序，实现CSI规范中定义的Identify、Node Service和可选的Controller Service。
2. 使用csi-sanity进行单元测试。
3. 定义Kubernetes API YAML 文件，用于部署 CSI Driver和适当的Sidecar Container。
4. 在Kubernetes集群上部署CSI Driver并在其上运行E2E功能测试。

## Overview

创建CSI Driver的第一步是编写实现CSI Spec中描述gRPC接口的应用程序，CSI Driver至少须实现以下两种CSI服务：
- CSI Identity
  - 使调用者（Kubernetes组件和CSI sidecar container）能够识别Driver及其支持的可选功能。
- CSI Node Service
  - 仅其中的NodePublishVolume、NodeUnpublishVolume和NodeGetCapabilities是必须实现的。
  - 必需的方法使调用者能够在指定的路径上提供可用的Volume并发现Driver支持哪些可选功能。

所有CSI服务都可以在同一个CSI Driver应用程序中实现。CSI Driver应用程序应该被容器化，以便在Kubernetes上轻松部署。容器化后，CSI Driver可以与CSI Sidecar Containers配对使用，并根据需要以Node和/或Controller模式部署。如果Driver支持附加功能，CSI capabilities可用于告知调用者它支持的可选方法/服务，例如：

- CONTROLLER_SERVICE（PluginCapability）
  - 整个CSI Controller Service是可选的。此功能指示Driver实现了CSI Controller Service中的一个或多个方法。
- VOLUME_ACCESSIBILITY_CONSTRAINTS（PluginCapability）
  - 此功能表明该Driver支持的Volume可能无法从集群中的所有节点同等访问，并且该Driver将返回额外的拓扑相关信息，Kubernetes 可以使用这些信息更智能地调度工作负载或影响配置Volume的位置。
- VolumeExpansion (PluginCapability)
  - 此功能表明Driver支持在创建后调整（扩展）卷的大小。
- CREATE_DELETE_VOLUME（ControllerServiceCapability）
  - 此功能表明Driver支持动态卷配置和删除。
- PUBLISH_UNPUBLISH_VOLUME（ControllerServiceCapability）
  - 此功能表明Driver实现了ControllerPublishVolume和ControllerUnpublishVolume —— 对应于 Kubernetes 卷附加/分离操作的操作。例如，这可能会导致针对 Google Cloud 控制平面的“卷附加”操作，以将指定卷附加到 Google Cloud PD CSI Driver的指定节点。
- CREATE_DELETE_SNAPSHOT (ControllerServiceCapability)
  - 此功能表明Driver支持供应卷快照以及使用这些快照供应新卷的能力。
- CLONE_VOLUME（ControllerServiceCapability）
  - 此功能表明Driver支持克隆卷。
- STAGE_UNSTAGE_VOLUME（NodeServiceCapability）
  - 此功能表明Driver实现了NodeStageVolume 和NodeUnstageVolume —— 对应于 Kubernetes 卷设备挂载/卸载操作的操作。例如，这可以用于创建块存储设备的全局（每个节点）卷安装。

## Kubernetes CSI Sidecar Containers

Kubernetes CSI Sidecar Containers是一组标准容器，目标是简化Kubernetes上CSI Driver的开发和部署。这些容器包含Watch Kubernetes API 对象的通用逻辑，触发针对CSI Driver容器的适当操作，并根据需要更新 Kubernetes API。使用这些Sidecar的好处包括：
1. CSI Driver开发人员不必担心复杂的Kubernetes代码。
2. 与 Kubernetes API 交互的代码与实现 CSI 接口的代码隔离（在不同的容器中）。

Kubernetes 开发团队维护以下 Kubernetes CSI Sidecar Containers： 

### [external-provisioner](https://github.com/kubernetes-csi/external-provisioner)
CSI external-provisioner 是一个 sidecar 容器，用于Watch PersistentVolumeClaim 对象。它调用CSI Driver的CreateVolume接口以供应新卷或者调用DeleteVolume接口删除卷。在 Kubernetes controller-manager中运行的内部PersistentVolume controller没有任何与CSI Driver交互的直接接口。

如果PVC引用了StorageClass，并且StorageClass的Provisioner字段与GetPluginInfo接口中返回的名称匹配，则卷的创建由该PersistentVolumeClaim对象的创建触发。当成功配置新卷后，该Sidecar容器会创建一个 Kubernetes PersistentVolume 对象来表示该卷。一旦与此PersistentVolume绑定的PersistentVolumeClaim被删除，对应CSI Driver的DeleteVolume接口会被调用。当该卷被成功删除时，Sidecar也会删除代表该卷的PersistentVolume对象。

支持动态卷Provision的 CSI Driver应该使用这个 sidecar 容器，并向外告知Driver支持CSI CREATE_DELETE_VOLUME。external-provisioner 可以与其他external CSI controller（例如 external-attacher、external-snapshotter 和/或 external-resizer）在同一个 pod 中运行。请注意，external-provisioner 不会随着更多副本进行扩展。只有一个external-provisioner被选为leader并运行。

#### Data Source

external-provisioner提供了从一个data source部署volume的能力。支持的data source包括：

>1. Snapshot 
>>如果将Snapshot CRD 指定为 PVC 对象上的数据源，则Sidecar通过获取`SnapshotContent`对象来获取有关快照的信息，并在调用`CreateVolume`时填充data source字段以向存储系统指示新卷应使用指定的快照填充。
>2. PersistentVolumeClaim(clone)
>>克隆是通过在`CreateVolume`调用中的`DataSource`字段中指定一种类型为`PersistentVolumeClaim`的`kind`来实现的。外部供应商有责任验证在 DataSource 中指定的对象是否存在，是否与正在供应的卷在同一存储类中，并且当前状态是绑定的。

#### StorageClass 参数
Provision新卷时，CSI external-provisioner将`CreateVolumeRequest`调用中的parameters(map<string, string>)字段设置为它正在处理的 StorageClass中指定的键/值。

CSI external-provisioner (v1.0.1+) 还保留了前缀为 csi.storage.k8s.io/ 的参数键。任何以 csi.storage.k8s.io/ 为前缀的 StorageClass 键都不会传递给 CSI Driver。

以下保留的 StorageClass 参数键会触发 CSI external-provisioner的行为：
- csi.storage.k8s.io/provisioner-secret-name
- csi.storage.k8s.io/provisioner-secret-namespace
- csi.storage.k8s.io/controller-publish-secret-name
- csi.storage.k8s.io/controller-publish-secret-namespace
- csi.storage.k8s.io/node-stage-secret-name
- csi.storage.k8s.io/node-stage-secret-namespace
- csi.storage.k8s.io/node-publish-secret-name
- csi.storage.k8s.io/node-publish-secret-namespace
- csi.storage.k8s.io/fstype

#### PersistentVolumeClaim and PersistentVolume 参数

CSI external-provisioner (v1.6.0+) 引入了 --extra-create-metadata 标志，它会在 CSI CreateVolumeRequest 中自动设置以下的parameters(map<string, string>)：

- csi.storage.k8s.io/pvc/name
- csi.storage.k8s.io/pvc/namespace
- csi.storage.k8s.io/pv/name

这些参数不是 StorageClass 的一部分，而是使用源 PersistentVolumeClaim 和 PersistentVolume 的名称和命名空间。

### [external-resizer](https://github.com/kubernetes-csi/external-resizer)

CSI external-resizer负责Watch PersistentVolumeClaim对象的更改，如果用户需要更多的Storage，则会调用`ControllerExpandVolume`接口。

支持Kubernetes volume expansion的 CSI Driver应该使用这个 sidecar 容器，并向外告知支持CSI VolumeExpansion。

### [external-attacher](https://github.com/kubernetes-csi/external-attacher)

CSI external-attacher负责Watch VolumeAttachment对象并调用`Controller[Publish|Unpublish]Volume`接口。

支持Kubernetes volume attach/detach的 CSI Driver应该使用这个 sidecar 容器，并向外告知支持CSI PUBLISH_UNPUBLISH_VOLUME。

### [node-driver-registrar](https://github.com/kubernetes-csi/node-driver-registrar)
CSI node-driver-registrar通过调用CSI Driver的NodeGetInfo接口获取信息，并使用Kubelet[插件注册](../05/plugin-registration.html)机制向该node上的Kubelet注册CSI Driver。

Kubelet 直接针对 CSI Driver发起 CSI NodeGetInfo、NodeStageVolume 和 NodePublishVolume 调用。所有CSI Driver的Node Plugin都应该使用这个 sidecar 容器向 kubelet 注册自己。

### [external-snapshotter](https://github.com/kubernetes-csi/external-snapshotter)

从Beta版本开始，snapshot controller会Watch VolumeSnapshot和VolumeSnapshotContent 对象。CSI external-snapshotter sidecar仅Watch VolumeSnapshotContent 对象。CSI external-snapshotter sidecar还负责调用三个CreateSnapshot、DeleteSnapshot和ListSnapshots RPC接口。

支持配置volume snapshots和使用这些snapshots配置新卷的能力的 CSI Driver应该使用这个 sidecar 容器，并通告 CSI CREATE_DELETE_SNAPSHOT controller功能。

CSI external-snapshotter被部署为sidecar controller。

#### VolumeSnapshotClass Parameters

配置新卷快照时，CSI external-snapshotter将CSI CreateSnapshotRequest调用中的parameters（map<string, string>）字段段设置为它正在处理的 VolumeSnapshotClass 中指定的键/值。

CSI external-snapshotter还保留以csi.storage.k8s.io/为前缀的参数键。任何以csi.storage.k8s.io/为前缀的VolumeSnapshotClass键都不会作为parameters传递给 CSI Driver。

以下保留的 VolumeSnapshotClass 参数键触发CSI external-snapshotter中的行为：
- csi.storage.k8s.io/snapshotter-secret-name (v1.0.1+)
- csi.storage.k8s.io/snapshotter-secret-namespace (v1.0.1+)
- csi.storage.k8s.io/snapshotter-list-secret-name (v2.1.0+)
- csi.storage.k8s.io/snapshotter-list-secret-namespace (v2.1.0+)

有关如何处理secrets的更多信息，请参阅[Secrets & Credentials](https://kubernetes-csi.github.io/docs/secrets-and-credentials.html)。

#### VolumeSnapshot and VolumeSnapshotContent Parameters

CSI external-snapshotter (v4.0.0+)引入了--extra-create-metadata标志，它会在CSI CreateSnapshotRequest调用中自动设置以下 parameters(map<string, string>)：
- csi.storage.k8s.io/volumesnapshot/name
- csi.storage.k8s.io/volumesnapshot/namespace
- csi.storage.k8s.io/volumesnapshotcontent/name

这些parameters是使用Source VolumeSnapshot和VolumeSnapshotContent的name和namespace在内部生成的。

### [livenessprobe](https://kubernetes-csi.github.io/docs/livenessprobe.html)

CSI livenessprobe 是一个 sidecar 容器，它监控 CSI Driver 的健康状况，并通过 Liveness Probe 机制将其报告给 Kubernetes。这使 Kubernetes 能够自动检测Driver的问题并重新启动 pod 以尝试修复问题。


liveness probe 是一个 sidecar 容器，它暴露了一个 HTTP /healthz 端点，它作为 kubelet 的 livenessProbe Hook来监控 CSI Driver的健康状况。

liveness probe使用 Probe() 调用来检查 CSI Driver是否健康。有关 Probe API 调用的更多信息，请参阅 CSI 规范。容器存储接口 (CSI)

### [external-health-monitor-controller](https://github.com/kubernetes-csi/external-health-monitor)
CSI external-health-monitor-controller 是一个 sidecar 容器，与 CSI Controller Driver一起部署，类似于 CSI external-provisioner sidecar 的部署方式。它调用 CSI 控制器 RPC ListVolumes 或 ControllerGetVolume 来检查 CSI 卷的健康状况，如果卷的状况异常，则在 PersistentVolumeClaim 上报告事件。

CSI external-health-monitor-controller 还Watch节点故障事件。可以通过将 enable-node-watcher 标志设置为 true 来启用此组件。这现在只会对本地 PV 产生影响。当检测到节点故障事件时，会在 PVC 上报告一个事件，表明使用该 PVC 的 Pod 位于故障节点上。

支持 VOLUME_CONDITION 和 LIST_VOLUMES 或 VOLUME_CONDITION 和 GET_VOLUME 控制器功能的 CSI Driver应该使用这个 sidecar 容器。

## CSI Object

### CSIDriver Object
CSIDriver Object有两个用途：

>1. 简化Driver的发现
>>  如果 CSI Driver创建了一个 CSIDriver 对象，Kubernetes 用户可以很容易地发现安装在他们集群上的 CSI Driver（只需发出 kubectl get CSIDriver）
>2. 自定义 Kubernetes 行为
>>  Kubernetes 在处理 CSI Driver时有一组默认行为（例如，它默认调用 Attach/Detach 操作）。此对象允许 CSI Driver指定 Kubernetes 应如何与其交互。

CSI Driver Object主要包括：
- name: CSI Driver 的名字
- attachRequired: 指示此 CSI volume Driver需要attach操作（因为它实现了 CSI ControllerPublishVolume 方法），并且 Kubernetes 应调用attach并等待任何attach操作完成，然后再继续挂载。则默认值为 true。
- podInfoOnMount: 表示此 CSI Driver在挂载操作期间需要额外的 pod 信息（如 pod 名称、pod UID 等）。默认为false。如果 value 设置为 true，Kubelet 将在 CSI NodePublishVolume 调用中将 pod 信息作为 volume_context 传递：
  - “csi.storage.k8s.io/pod.name”：pod.Name
  - “csi.storage.k8s.io/pod.namespace”：pod.Namespace
  - “csi.storage.k8s.io/pod.uid”：pod.UID
  - “csi.storage.k8s.io/serviceAccount.name”：pod.Spec.ServiceAccountName
- fsGroupPolicy: 控制此 CSI 卷Driver是否在安装卷时支持卷所有权和权限更改。支持以下模式，如果未指定，则默认为 ReadWriteOnceWithFSType：
  - None：表示卷将在没有修改的情况下挂载，因为 CSI 卷Driver不支持这些操作。
  - File：表示 CSI 卷驱动支持通过 fsGroup 更改卷所有权和权限，Kubernetes 可以使用 fsGroup 更改卷的权限和所有权，以匹配 pod 的 SecurityPolicy 中用户请求的 fsGroup，而不管 fstype 或访问模式如何。
  - ReadWriteOnceWithFSType：表示将检查卷以确定是否应修改卷所有权和权限以匹配 pod 的安全策略。仅当定义了 fsType 并且持久卷的 accessModes 包含 ReadWriteOnce 时才会发生更改。如果没有定义其他 FSGroupPolicy，这是默认行为。
- volumeLifecycleModes: 它通知 Kubernetes Driver支持的卷模式。这样可以确保Driver不会被用户错误地使用。默认为 Persistent，这是正常的 PVC/PV 机制。
- tokenRequests: 如果指定了该字段，Kubelet 将在 NodePublishVolume 中将绑定pod的服务帐户令牌作为 volume_context
  - "csi.storage.k8s.io/serviceAccount.tokens": {"gcp":{"token":"<token>","expirationTimestamp":"<RFC3339 中的过期时间戳>"}}
  - 如果 CSI Driver没有找到 volume_context 中记录的令牌，它应该在 NodePublishVolume 中返回错误以通知 Kubelet 重试。
  - Audiences应该是不同的，否则验证将失败。如果Audiences为“”，则表示发行的令牌与 kube-apiserver 具有相同的Audiences。
- requiresRepublish: 如果该字段为true，Kubelet 会定期调用 NodePublishVolume。这在以下情况下很有用：
  - 如果 CSI Driver挂载的卷是short-lived。
  - 如果 CSI Driver重复需要有效的服务帐户令牌（由字段 tokenRequests 启用）。
```
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: mycsidriver.example.com
spec:
  attachRequired: true
  podInfoOnMount: true
  fsGroupPolicy: File # added in Kubernetes 1.19, this field is GA as of Kubernetes 1.23
  volumeLifecycleModes: # added in Kubernetes 1.16, this field is beta
    - Persistent
    - Ephemeral
  tokenRequests: # added in Kubernetes 1.20. See status at https://kubernetes-csi.github.io/docs/token-requests.html#status
    - audience: "gcp"
    - audience: "" # empty string means defaulting to the `--api-audiences` of kube-apiserver
      expirationSeconds: 3600
  requiresRepublish: true # added in Kubernetes 1.20. See status at https://kubernetes-csi.github.io/docs/token-requests.html#status
``` 

要安装，CSI Driver的部署清单必须包含一个 CSIDriver 对象，如上例所示。

CSIDriver 实例应该存在于所有使用相应 CSI Driver提供的卷的 Pod 的整个生命周期中，因此 Skip Attach 和 Pod Info on Mount 功能可以正常工作。

### CSINode Object

CSI Driver会生成节点特定信息。但是这些信息不是存储在 Kubernetes Node API 对象中，而是创建了一个新的 CSI 特定的 Kubernetes CSINode 对象。它有以下用途：
- 将 Kubernetes 节点名称映射到 CSI 节点名称，
  - CSI GetNodeInfo 接口会返回存储系统引用的节点名称。Kubernetes 必须在以后的 ControllerPublishVolume 调用中使用此名称。因此，当注册新的 CSI Driver时，Kubernetes 会将存储系统的Node ID 存储在 CSINode 对象中以供将来使用。
- CSI Driver是否可用
  - 一种kubelet 通知 kube-controller-manager 和 kubernetes scheduler CSI Driver在节点上是否可用（已注册）的方法。
- Volume topology
  - CSI GetNodeInfo 接口会返回一组标识该节点拓扑结构的键/值标签。 Kubernetes 使用此信息进行拓扑感知配置。它将键/值作为标签存储在 Kubernetes Node对象上。为了记录哪些 Node 标签属于特定的 CSI Driver，kubelet 将这些键存储在 CSINode 对象中以供将来参考。

CSINode Object主要包括：
- Drivers: 在节点上运行的 CSI Driver列表及其属性。
- name: 此对象引用的 CSI Driver。
- nodeID: 由Driver确定的NodeId
- topologyKeys: Driver支持的分配给节点的拓扑键列表。

```
apiVersion: storage.k8s.io/v1
kind: CSINode
metadata:
  name: node1
spec:
  Drivers:
  - name: mycsidriver.example.com
    nodeID: storageNodeID1
    topologyKeys: ['mycsidriver.example.com/regions', "mycsidriver.example.com/zones"]
```

CSI Driver不需要直接创建CSINode对象。当 CSI Driver通过 kubelet 插件注册机制注册时，kubelet会管理该对象。node-driver-registrar sidecar 容器有助于此注册。

## Deployment in Kubernetes

CSI Driver通常作为两个组件部署在 Kubernetes 中：controller和每个节点上的组件。

### Controller Plugin

Controller Plugin可以作为 Deployment 或 StatefulSet 部署在集群中的任何节点上。 它由实现 CSI Controller 服务的 CSI Driver和一个或多个 sidecar 容器组成。 这些控制器sidecar容器通常与 Kubernetes 对象交互并调用Driver的 CSI 接口。

它通常不需要直接访问宿主机，通过 Kubernetes API 和external control plane服务执行其所有操作。 可以为 HA 部署多个副本，但是建议使用leader election来确保一次只有一个活动Controller。

控制器 sidecar 包括：
- external-provisioner
- external-attacher
- external-snapshotter
- external-resizer。 

在部署中包含 sidecar 是可选的。Sidecar 容器管理 Kubernetes event并对 CSI Driver进行适当的调用。 调用是通过 sidecar 和 CSI Driver之间的 emptyDir 卷共享 Unix Domain Socket来进行的。


### Node Plugin

Node Plugin应该通过 DaemonSet 部署在集群中的每个节点上。 它由实现 CSI Node Service的 CSI Driver和node-driver-registrar sidecar容器组成。

Node上运行的Kubelet会调用 CSI Node Service，从存储系统中挂载和卸载存储卷，使其可供 Pod 使用。 Kubelet通过使用Host上的HostPath Volume共享的UNIX domain socket 调用 CSI Driver。 此外还有另一个UNIX domain socket，node-driver-registrar 使用它来将 CSI Driver注册到 Kubelet。

#### Driver Volume Mounts
节点插件需要直接访问主机以使块设备和/或文件系统挂载可用于 Kubernetes kubelet。

CSI Driver使用的挂载点必须设置为双向，以允许主机上的 Kubelet 看到由 CSI Driver容器创建的挂载。 请参见下面的示例：
```
      containers:
      - name: my-csi-driver
        ...
        volumeMounts:
        - name: socket-dir
          mountPath: /csi
        - name: mountpoint-dir
          mountPath: /var/lib/kubelet/pods
          mountPropagation: "Bidirectional"
      - name: node-driver-registrar
        ...
        volumeMounts:
        - name: registration-dir
          mountPath: /registration
      volumes:
      # This volume is where the socket for kubelet->driver communication is done
      - name: socket-dir
        hostPath:
          path: /var/lib/kubelet/plugins/<driver-name>
          type: DirectoryOrCreate
      # This volume is where the Driver mounts volumes
      - name: mountpoint-dir
        hostPath:
          path: /var/lib/kubelet/pods
          type: Directory
      # This volume is where the node-driver-registrar registers the plugin
      # with kubelet
      - name: registration-dir
        hostPath:
          path: /var/lib/kubelet/plugins_registry
          type: Directory
```