---
title: Presto Overview
tags: Presto
---


大量的数据以不同的格式提供，由不同的数据源提供，并且可以使用不同的查询语言进行搜索。此外，在搜索有价值的见解时，用户需要非常快的结果，因此需要高性能的查询引擎系统。这些挑战促使 Facebook（现为 Meta）、Airbnb、Uber 和 Netflix 等公司重新思考他们管理数据的方式。他们逐渐从基于数据仓库的旧模式转向数据湖房。虽然数据仓库管理结构化数据和历史数据，但数据湖库还可以管理非结构化数据和实时数据并从中获取见解。

Presto 是解决之前挑战的一个可能的解决方案。 Presto 是一个分布式 SQL 查询引擎，由 Facebook 创建并大规模使用。可以轻松地将 Presto 集成到数据湖中，以构建快速运行的 SQL 查询，无论数据的原始格式如何，无论数据位于何处，这些查询都可以与数据进行交互。

<!--more-->

## Data Warehouses and Data Lakes

数据主要分为三种类型：
- 结构化数据
- 半结构化数据
- 非结构化数据

|||||
|-|-|-|-|
||Structured Data|Semi-structured data|Unstructured Data|
|Description|Data is organized in a fixed schema|Data is partially organized without a fixed schema|Data is not organized|
|Typical formats|SQL, CSV|JSON, XML|audio, video, text|
|Pros|Easy to derive insights|More flexible than structured data|Very scalable|
|Cons|Schema dependence limits scalability|The meta-level structure may contain unstructured data|Difficult to search|
|Examples|Database|Annotated texts, such as tweets with hashtag|plain text, digital photos|

根据支持的数据类型及其组织和处理方式，有不同的数据存储系统。数据仓库是仅包含结构化数据的中央存储库，用于报告和分析。数据仓库的总体架构主要有四个层：
- 结构化数据: 包括多个来源提供的结构化数据，例如关系数据库系统
- 提取、转换和加载 (ETL): 即将数据转换为正确格式的过程
- 数据仓库: 其中包含可供最终层使用的数据
- 报告、仪表板和数据挖掘是使用数据仓库中包含的数据的最后一层

![data_warehouse](../../../assets/images/posts/data_warehouse.png)

随着大数据时代的到来，数据仓库背后的底层架构已被证明不足以管理大量数据。 Facebook 等大公司在使用数据仓库时存在以下问题：
- 非结构化数据：由于数据仓库管理结构化数据，因此它不能用于存储原始非结构化数据，例如文本或音频。在将非结构化数据引入数据仓库之前，您必须对其进行处理。
- 可扩展性：随着摄取数据和分析处理量的不断增加，数据仓库的技术成本会呈非线性增长。
- 实时数据：数据仓库不适合近实时数据，因为数据必须先结构化才能使用。


数据湖解决了这些问题。数据湖的总体架构如图所示:

![data_lakehouse](../../../assets/images/posts/data_lakehouse.png)

与数据仓库不同，数据湖管理并提供使用或处理结构化、半结构化和非结构化数据的方法。摄取原始数据使得数据湖能够摄取存储系统中的历史数据和实时数据。随着时间的推移，数据湖的概念已经演变为数据湖屋的概念，这是一个增强的数据湖，其顶部包括对事务的支持。在实践中，数据湖屋按照数据仓库语义修改数据湖中的现有数据。

早期的数据湖称为本地数据湖，安装在公司的服务器上。这种类型的数据湖的主要优点是公司对系统的完全控制。随着云计算的出现，数据湖已经转移到云端，将管理、维护和安全问题留给了云提供商及其客户，他们负责数据的安全。这称为云数据湖，并且越来越受欢迎。提供云数据湖的主要平台是 Amazon Web Services (AWS)、Azure 和 Google Cloud（通过对象存储）。

为了使数据可供上层（仪表板、报告和数据挖掘）访问，数据湖提供了一个中间层，称为元数据和治理，以保证数据一致性和安全控制。

## Presto 的来源

Facebook 于 2012 年实现了 Presto，以解决 Apache Hive 带来的问题，Apache Hive 是一个位于连接到数据湖的 Hadoop Map-Reduce 框架之上的分布式 SQL 引擎。Apache Hive 是 Facebook 当时使用的数据仓库之一。 Apache Hive 的主要问题是处理大量数据时速度缓慢。

Apache Hive 最初也是由 Facebook 在 2010 年开发并开源的。当时，Apache Hive 的底层架构是 MapReduce，它利用中间数据集来持久化到磁盘。这需要频繁地对磁盘进行 I/O 访问以获取瞬态中间结果集的数据。

为了克服这些问题，Facebook 开发了 Presto，这是一种新的分布式 SQL 查询引擎，设计为内存引擎，无需保留单个查询的中间结果集。这种方法使得查询引擎处理相同查询的速度提高了几个数量级，许多查询的延迟时间不到一秒。

![hive_vs_presto](../../../assets/images/posts/hive_vs_presto.png)

展示了Presto和Hive如何执行查询。 Hive 使用 MapReduce 框架来运行查询。实际上，它将中间结果存储到磁盘：在map和reduce阶段之后，中间结果都存储在磁盘中。相反，Presto 通过在工作计算机的内存中执行查询来节省时间，包括对其中的中间数据集执行操作，而不是将它们保存到磁盘。

## Presto 是什么

Presto 是一个开源的分布式 SQL 查询引擎，支持结构化和半结构化数据源。可以使用 Presto 直接在数据所在位置查询数据，就像数据湖一样，而无需将它们移动到另一个系统。 Presto 通过基于内存的架构并发运行查询，从而使其非常快速且可扩展。

在数据湖架构中，可以想象 Presto 适合治理和元数据层。通过 Presto，可以非常快速高效地查询云数据湖。 Presto 直接在内存中执行查询。避免在阶段之间从磁盘写入和读取的需要最终会加快查询执行时间。

Presto coordinator machine分析用 SQL 编写的任何查询，支持 ANSI SQL 标准，在连接到数据湖的 Presto Worker集群上创建和调度query plan，然后返回查询结果。根据查询的不同，查询计划可能有多个执行stage。

不要因为 Presto 提供了标准数据库的功能就误认为 Presto 理解 SQL。 Presto 不是通用的关系数据库。它不能替代 MySQL、PostgreSQL 或 Oracle 等数据库。 Presto 并不是为处理在线事务处理 (OLTP) 而设计的。

Presto 是一款旨在使用分布式查询以高效查询大量数据的工具。如果处理的数据是 TB 或 PB 量级，可能会使用与 Hadoop 和 HDFS 交互的工具。 Presto 被设计为使用 Hive 或 Pig 等 MapReduce pipelines 查询 HDFS 的工具，但 Presto 不仅仅限于访问 HDFS。 Presto 还可以在其他不同类型的数据源上运行，包括传统关系数据库和 Cassandra 等其他数据源。

Presto 旨在处理data warehousing和analytics：数据分析、聚合大量数据并生成报告。这些工作负载通常被归类为在线分析处理 (OLAP)。

## Concepts

语句和查询很容易理解，作为最终用户，还应该熟悉Stages和Splits等概念，以充分利用 Presto 执行高效的查询。作为 Presto 管理员或 Presto 贡献者，应该了解 Presto 的Stage概念如何映射到task以及task如何包含一组处理数据的drivers。

### Server Types

Presto 服务器分为三种类型：
- resource manager
- coordinators
- workers

#### Resource Manager


Presto Resource Manager是聚合来自所有coordinators和workers的数据并构建集群全局视图的服务器。具有 disaggregated coordinators 的 Presto 安装必须需要Resource Manager。集群支持多个Resource Manager，每个Resource Manager都充当主Resource Manager。

coordinators和workers使用 Thrift API 与Resource Manager进行通信。

#### Coordinator

Presto Coordinator 是负责解析语句、规划查询和管理Presto工作节点的服务器。它是 Presto 安装的“大脑”，也是客户端连接以提交执行语句的节点。每个 Presto 安装都必须有一名 Presto Coordinator 和一名或多名 Presto Worker。出于开发或测试目的，可以将单个 Presto 实例配置为执行这两个角色。

Coordinator 跟踪每个 Worker 的活动并协调查询的执行。 Coordinator 创建涉及一系列Stages的查询的逻辑模型，然后将其转换为在 Presto 工作集群上运行的一系列connected tasks。

Coordinator 使用 REST API 与 Worker 和 Client 进行通信。

#### Worker

Presto Worker 是 Presto 安装中的server，负责执行 Task 和处理数据。 Worker node 从 connectors 获取数据并相互交换中间数据。 Coordinator 负责从Worker 那里获取结果并将最终结果返回给客户端。

当 Presto worker启动时，它会将自己通告给 Coordinator 中的 discovery 服务器，这使其可供 Presto Coordinator 执行 Task 。

worker 使用 REST API 与其他 worker 和 Presto Coordinator 进行通信。

### Data Sources

connector, catalog, schema, and table这些基本概念涵盖了特定数据源的 Presto 模型，并在以下部分中进行了描述。

#### Connector

Connector 使 Presto 适应 Hive 或关系数据库等数据源。可以像考虑数据库 driver 一样来考虑Connector。它是 Presto SPI 的实现，允许 Presto 使用标准 API 与资源交互。

Presto 包含多个内置 Connector：用于 JMX 的 Connector、提供对内置系统表的访问的System Connector 、Hive  Connector 以及设计用于提供 TPC-H 基准数据的 TPCH  Connector 。许多第三方开发人员贡献了 Connector ，以便 Presto 可以访问各种数据源中的数据。

每个 catalog 都与特定的 Connector 相关联。如果检查 catalog 配置文件，将看到每个配置文件都包含一个强制属性connector.name，catalog manager使用该属性为给定 catalog 创建 Connector 。可以让多个 catalog 使用相同的 Connector 来访问相似数据库的两个不同实例。例如，如果您有两个 Hive 集群，则可以在单个 Presto 集群中配置两个 catalog，这两个目录都使用 Hive Connector ，从而允许您从两个 Hive 集群查询数据（即使在同一 SQL 查询中）。

#### Catalog

Presto catalog 包含 schemas 并通过 Connector 引用数据源。例如，可以配置 JMX Catalog 以通过 JMX Connector 提供对 JMX 信息的访问。在 Presto 中运行 SQL 语句时，是针对一个或多个 catalog 运行它。catalog 的其他示例包括用于连接到 Hive 数据源的 Hive catalog。

在 Presto 中addressing table时，fully-qualified 的表名称始终植根于一个 catalog 中。例如，fully-qualified 表名称 hive.test_data.test 将引用 hive catalog 中 test_data scheme中的测试表。Catalog 在 Presto 配置目录中的属性文件中定义。

#### Schema

Schema 是一种组织表格的方法。Catalog 和 Schema 一起定义了一组可以查询的表。当使用 Presto 访问 Hive 或 MySQL 等关系数据库时，schema 会转换为目标数据库中的相同概念。其他类型的Connector可能会选择以对底层数据源有意义的方式将表组织到 Schema 中。

#### Table

表是一组无序的行，它们被组织成具有类型的命名列。这与任何关系数据库中的情况相同。从源数据到表的映射由 Connector 定义。

### Query Execution Model

Presto 执行 SQL 语句并将这些语句转换为跨Coordinator和Worker的分布式集群执行的查询

#### Statement

Presto 执行 ANSI 兼容的 SQL 语句。当 Presto 文档引用语句时，它指的是 ANSI SQL 标准中定义的语句，其中包含子句、表达式和谓词。

有些读者可能会好奇为什么本节列出了 Statement 和 Query 的单独概念。这是必要的，因为在 Presto 中，语句仅代表 SQL 语句的文本表示。执行语句时，Presto 会创建一个 Query 以及一个 Query Plan，然后将其分发到一系列 Presto workers中。

#### Query

当 Presto 解析语句时，它将其转换为 Query 并创建分布式 Query Plan，然后将其实现为在 Presto Worker 上运行的一系列 interconnected stages。当在 Presto 中检索有关Query的信息时，会收到参与生成响应语句的结果集的每个组件的快照。

语句和查询之间的区别很简单。语句可以被认为是传递给 Presto 的 SQL 文本，而查询是指为执行该语句而实例化的配置和组件。查询包含Stage、Task、 Splits、Connectors以及协同工作以产生结果的其他组件和数据源。

#### Stage

当 Presto 执行查询时，它通过将执行分解为分层的Stage结构来实现。例如，如果 Presto 需要聚合 Hive 中存储的 10 亿行数据，它会通过创建一个root stage来聚合其他几个stage的输出来实现这一目的，所有这些stage都旨在实现分布式查询计划的不同部分。

组成查询的阶段层次结构类似于树。每个查询都有一个root stage，负责聚合其他stage的输出。Coordinator使用stage来建模分布式查询计划，但stage本身并不在 Presto worker上运行。

#### Task

正如上一节中提到的，Stage对分布式查询计划的特定部分进行建模，但Stage本身并不在 Presto Worker 上执行。要了解Stage是如何执行的，需要了解Stage是作为分布在 Presto Worker网络上的一系列Task来实现的。

Task是 Presto 架构中的 “work horse”，因为分布式查询计划被解构为一系列Stage，然后将这些Stage转换为Task，然后对Task进行操作或Splits。 Presto  Task 具有输入和输出，正如一个Stage可以由一系列task并行执行一样，task 也可以与一系列drivers并行执行。


#### Split

Task 对 Splits 进行操作， Split 是较大数据集的一部分。分布式查询计划最低级别的 Stage 通过Connector的 Split 检索数据，分布式查询计划较高级别的中间Stage从其他Stage检索数据。

当 Presto 调度查询时， coordinator 将查询 Connector 以获取可用于表的所有 Splits 的列表。 coordinator 跟踪哪些机器正在运行哪些 Task 以及哪些 Task 正在处理哪些Split。

#### Driver

Task 包含一个或多个并行 Driver。 Driver对数据进行操作并组合运算以生成输出，然后由Task聚合该输出，然后将其传递给另一个Stage的另一个Task。 Driver  是一系列运算实例，或者可以将 Driver 视为内存中的一组物理运算器。它是 Presto 架构中最低级别的并行性。Driver有一个输入和一个输出。

#### Operator

Operator消费、转换和生成数据。例如，表扫描从 Connector 获取数据并生成可由其他Operator使用的数据，而过滤 Operator 使用数据并通过对输入数据应用谓词来生成子集。

#### Exchange 

Exchange 在 Presto 节点之间传输数据以进行查询的不同 Stage。Task 将数据生成到输出缓冲区中，并使用Exchange客户端消耗来自其他Task的数据

## Architecture and Core Components

![presto_architecture](../../../assets/images/posts/presto_architecture.png)


上图图显示了 Presto 架构，它部署为两种主要 Service：
- 一个Coordinator
- 许多Wokers

Coordinator 实际上是操作的大脑，接收来自客户端的查询请求，解析查询，构建执行计划，然后调度要在许多Worker中完成的工作。Coordinator 包含三个主要组件：
- parser
- planner
- scheduler

worker并行地处理整个查询的一部分，可以增加 Woker 到 Presto 部署中以满足需求。每个数据源都配置为一个Catalog，可以在每个查询中查询任意数量的Catalog。

可以通过三种不同的方式配置 Presto：
- 只有一个数据源：用户可以使用 Presto 查询单个数据源。在这种情况下，Presto 成为独立的查询引擎，它使用External Catalog中的元数据并处理存储在数据湖中的数据。
- 独立查询多个数据源：作为联合引擎，可以看到许多连接到多个数据源的 Presto 部署。这允许最终用户使用相同的界面一次查询一个数据源，而无需在系统之间切换或将它们视为不同的数据系统。
- 通过将多个数据源一起关联和查询：将联合更进一步，查询可以组合来自两个或多个不同数据源的数据。这样做的好处是允许最终用户分析更多数据，而无需将数据移动或复制到单个数据源中。

## [Benchmark](https://github.com/prestodb/presto/tree/master/presto-benchto-benchmarks)

Benchmark 是 Presto 评估中的一个关键组成部分，它有助于识别各种操作期间的系统资源需求和使用情况及其相关的延迟指标。通常的做法是对一小组数据运行查询并获取性能数据，但对大规模数据运行时可能并非如此。对于大规模数据，应该查看各种操作的整体性能而不是单个操作结果。

为了进行基准测试，我们将使用开源工具 benchto，它是 Presto 项目的一部分，它可以运行行业标准 TPC-H 数据库应用程序。

### TPC-H

基于 tpc.org，TPC-H 是一个 decision-support 的基准。它由一套面向业务的查询和并发数据修改组成。查询和数据的选择充分地考虑了广泛的行业相关性。该基准测试展示了一套 decision-support 系统，该系统会检查大量数据、执行高度复杂的查询并给出关键业务问题的答案。

TPC-H 配备了各种数据集大小来测试不同的缩放因子。

|SF(GigaBytes)|Size|
|-|-|
|1|Consists of the base row size (several million elements).|
|10|Consists of the base row size x 10.|
|100|Consists of the base row size x 100 (several hundred million elements).|
|1000|Consists of the base row size x 1000 (several billion elements).|

TPC-H 规范是一份 137 页的文档，但总结一下：
- 数据库由第三范式(3NF) 架构组成，该架构由8 个表组成。
- 可以使用预定的数据库大小（称为“比例因子”）来运行基准测试。每个比例因子对应于数据仓库的原始数据大小。
- 8 个表中的 6 个随比例因子线性增长，并填充均匀分布的数据。
- 并行运行22 个复杂且长时间运行的查询模板和2 个数据刷新进程（插入和删除）以测试并发性。
- 并发进程的数量随着比例因子的增加而增加 —— 例如，对于100 GB 基准测试，会运行5 个并发进程。

### [Benchto Tool](https://github.com/prestodb/benchto)

Benchto 包括以下组件：
- Benchto Service: 充当持久数据存储来存储基准测试结果。
- Benchto Driver: 一个基于Java 的应用程序，加载 Benchmark Descriptors 的定义并在 Presto 集群上执行它们。如果集群监控到位，那么它会收集资源指标，例如集群的 CPU、内存、网络使用情况。
- 集群资源使用情况监控是使用 Grafana/Graphite 完成的。

![benchto-high-level-architecture](../../../assets/images/posts/benchto-high-level-architecture.png)


### [Benchto Service Setup](https://github.com/prestodb/benchto/blob/master/benchto-service/README.md)

1. Install and export JAVA 8 and JDK
2. `git clone git@github.com:prestodb/benchto.git`
3. Install JDBC for JAVA 8: https://jdbc.postgresql.org/download/, edit pom.xml in benchto repo with the righ JDBC.
4. Start postgres
    ```
    $ docker run --name benchto-postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 -d postgres
    ```
5. Run integration tests
    ```
    $ ./mvnw verify
    ```
6. Run benchto-service
    ```
    env SERVER_PORT=8081 ./mvnw spring-boot:run -pl benchto-service
    ```
    Go to: http://localhost:8081/
7. To create environment PRESTO-DEVENV you need to run:
    ```
    $ curl -H 'Content-Type: application/json' -d '{
    "dashboardType": "grafana",
    "dashboardURL": "http://localhost:3000/dashboard/db/presto-devenv",
    "prestoURL": "http://presto-master:8080/"
    }' http://localhost:8081/v1/environment/PRESTO-DEVENV
    ```
8. To create tag for environment PRESTO-DEVENV you need to run:
    ```
    $ curl -H 'Content-Type: application/json' -d '{
        "name": "Short tag desciption",
        "description": "Very long but optional tag description"
    }' http://localhost:8081/v1/tag/PRESTO-DEVENV
    ```
### [Benchto Driver Setup](https://github.com/prestodb/presto/tree/master/presto-benchto-benchmarks#configuring-benchmarks)

benchto-driver 是一个 Java 应用程序，它加载要运行的查询并针对想要测试的分布式系统进行测试。Presto 项目已经提供了 Presto Driver。我们可以使用该Driver 针对 Presto 集群运行基准测试。 Presto Driver 作为 presto-benchto-benchmarks 模块安装。Benchto Driver需要知道两件事：
- 要运行什么基准测试
- 以及要在什么环境上运行

出于以下示例的目的，我们将使用:
- tpch 基准测试
- 在 your.presto.coordinator.com:8080 运行的 Presto Service
- 以及在 localhost:8081 运行的 Benchto Service。

Benchto Driver 使用Sprint Boot来定位环境配置文件。需要在当前目录（即调用基准测试的目录）中放置一个 application-presto-devenv.yaml 文件，其中包含以下内容：

```
benchmark-service:
  url: http://localhost:8081

data-sources:
  presto:
    url: jdbc:presto://your.presto.coordinator.com:8080
    username: na (optional)
    password: na (optional)
    driver-class-name: com.facebook.presto.jdbc.PrestoDriver

environment:
  name: PRESTO-DEVENV

presto:
  url: http://your.presto.coordinator.com:8080

benchmark:
  feature:
    presto:
      metrics.collection.enabled: true

macros:
  sleep-4s:
    command: echo "Sleeping for 4s" && sleep 4
```

可以使用 benchto-driver 覆盖功能来覆盖benchmark variables。例如，当想要使用不同数量的基准测试运行或不同的底层 schemas 时，这非常有用。创建一个简单的 overrides.yaml 文件：
```
runs: 10
tpch_medium: tpcds_10gb_txt
```

按照上述方式设置后，可以使用以下命令运行基准测试：
```
./mvnw clean package -pl presto-benchto-benchmarks
java -Xmx1g -jar presto-benchto-benchmarks/target/presto-benchto-benchmarks-*-executable.jar \
    --sql presto-benchto-benchmarks/src/main/resources/sql \
    --benchmarks presto-benchto-benchmarks/src/main/resources/benchmarks \
    --activeBenchmarks=presto/tpch --profile=presto-devenv \
    --overrides overrides.yaml
```