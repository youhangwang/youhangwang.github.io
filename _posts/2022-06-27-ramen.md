---
title: Ramen(Openshift DR)
tags: ODF DR Ramen
---

`Ramen`是一个`OCM`的placement extension，它可以跨托管集群为工作负载及其持久数据提供failover和relocation服务。`Ramen`提供云原生接口来协调工作负载及其在PersistentVolume中的数据，包括：
- 将工作负载重新定位到Peer Cluster，以实现跨集群的计划迁移
- 由于集群的意外丢失，将该集群上正在工作的负载恢复到对等集群

`Ramen`依赖于提供`CSI storage replication addon`的存储插件，其中`ceph-csi`是一个实现示例。
<!--more-->

Ramen程序主要分为两部分：
- dr-hub：在hub cluster上运行的controller
  - DRPolicy
  - DRCluster
  - DRPlacementControl
- dr-cluster：在受管集群上运行的controller
  - VolumeReplicationGroup
  - ProtectedVolumeReplicationGroupList

```
	if controllers.ControllerType == ramendrv1alpha1.DRHubType {
		utilruntime.Must(plrv1.AddToScheme(scheme))
		utilruntime.Must(ocmworkv1.AddToScheme(scheme))
		utilruntime.Must(viewv1beta1.AddToScheme(scheme))
		utilruntime.Must(cpcv1.AddToScheme(scheme))
		utilruntime.Must(gppv1.AddToScheme(scheme))
	} else {
		utilruntime.Must(volrep.AddToScheme(scheme))
		utilruntime.Must(volrep.AddToScheme(scheme))
		utilruntime.Must(volsyncv1alpha1.AddToScheme(scheme))
		utilruntime.Must(snapv1.AddToScheme(scheme))
	}
```

```
    if controllers.ControllerType == ramendrv1alpha1.DRHubType {
		if err := (&controllers.DRPolicyReconciler{
			Client:            mgr.GetClient(),
			APIReader:         mgr.GetAPIReader(),
			Scheme:            mgr.GetScheme(),
			ObjectStoreGetter: controllers.S3ObjectStoreGetter(),
		}).SetupWithManager(mgr); err != nil {
			setupLog.Error(err, "unable to create controller", "controller", "DRPolicy")
			os.Exit(1)
		}

		if err := (&controllers.DRClusterReconciler{
			Client:            mgr.GetClient(),
			APIReader:         mgr.GetAPIReader(),
			Scheme:            mgr.GetScheme(),
			MCVGetter:         rmnutil.ManagedClusterViewGetterImpl{Client: mgr.GetClient()},
			ObjectStoreGetter: controllers.S3ObjectStoreGetter(),
		}).SetupWithManager(mgr); err != nil {
			setupLog.Error(err, "unable to create controller", "controller", "DRCluster")
			os.Exit(1)
		}

		if err := (&controllers.DRPlacementControlReconciler{
			Client:    mgr.GetClient(),
			APIReader: mgr.GetAPIReader(),
			Log:       ctrl.Log.WithName("controllers").WithName("DRPlacementControl"),
			MCVGetter: rmnutil.ManagedClusterViewGetterImpl{Client: mgr.GetClient()},
			Scheme:    mgr.GetScheme(),
			Callback:  func(string, string) {},
		}).SetupWithManager(mgr); err != nil {
			setupLog.Error(err, "unable to create controller", "controller", "DRPlacementControl")
			os.Exit(1)
		}

		return
	}

	// Index fields that are required for VSHandler
	if err := volsync.IndexFieldsForVSHandler(context.Background(), mgr.GetFieldIndexer()); err != nil {
		setupLog.Error(err, "unable to index fields for controller", "controller", "VolumeReplicationGroup")
		os.Exit(1)
	}

	if err := (&controllers.ProtectedVolumeReplicationGroupListReconciler{
		Client:         mgr.GetClient(),
		Scheme:         mgr.GetScheme(),
		APIReader:      mgr.GetAPIReader(),
		ObjStoreGetter: controllers.S3ObjectStoreGetter(),
	}).SetupWithManager(mgr); err != nil {
		setupLog.Error(err, "unable to create controller", "controller", "ProtectedVolumeReplicationGroupList")
		os.Exit(1)
	}

	if err := (&controllers.VolumeReplicationGroupReconciler{
		Client:         mgr.GetClient(),
		APIReader:      mgr.GetAPIReader(),
		Log:            ctrl.Log.WithName("controllers").WithName("VolumeReplicationGroup"),
		ObjStoreGetter: controllers.S3ObjectStoreGetter(),
		Scheme:         mgr.GetScheme(),
	}).SetupWithManager(mgr); err != nil {
		setupLog.Error(err, "unable to create controller", "controller", "VolumeReplicationGroup")
		os.Exit(1)
	}
```

## DR HUB

### DR Policy Controller
```
type DRPolicySpec struct {
	// scheduling Interval for replicating Persistent Volume
	// data to a peer cluster. Interval is typically in the
	// form <num><m,h,d>. Here <num> is a number, 'm' means
	// minutes, 'h' means hours and 'd' stands for days.
	// +kubebuilder:validation:Required
	// +kubebuilder:validation:Pattern=`^\d+[mhd]$`
	SchedulingInterval string `json:"schedulingInterval,omitempty"`

	// Label selector to identify all the VolumeReplicationClasses.
	// This selector is assumed to be the same for all subscriptions that
	// need DR protection. It will be passed in to the VRG when it is created
	//+optional
	ReplicationClassSelector metav1.LabelSelector `json:"replicationClassSelector,omitempty"`

	// Label selector to identify all the VolumeSnapshotClasses.
	// This selector is assumed to be the same for all subscriptions that
	// need DR protection. It will be passed in to the VRG when it is created
	//+optional
	VolumeSnapshotClassSelector metav1.LabelSelector `json:"volumeSnapshotClassSelector,omitempty"`

	// List of DRCluster resources that are governed by this policy
	DRClusters []string `json:"drClusters,omitempty"`
}
```
DR Policy Controller会watch DR Policy，当前namespace中名为`ramen-hub-operator-config`的configmap，当前namespace中的secret。主要作用有：
1. 验证DR Policy 中包含的DRCluster是否存在。验证Policy之间是否有Conflicts。如果两个drpolicy具有相同的cluster，同时有一个drpolicy是支持Metro DR的，那么这两个Policy会发生冲突。
2. 添加label `cluster.open-cluster-management.io/backup=resource`和finalizer `drpolicies.ramendr.openshift.io/ramen`
3. 如果配置中启用了`DrClusterOperator.DeploymentAutomationEnabled` 和`DrClusterOperator.S3SecretDistributionEnabled`，则将S3 Secret部署到受管集群中。
  - 3.1 创建PlacementRuleBinding，binding Placement Rule 到 Policy
  - 3.2 创建Policy 包含想要部署的S3 Secret
  - 3.3 创建Placement Rule，将policy rule分发至所有的受管集群。

### DR Cluster Controller

```
// DRClusterSpec defines the desired state of DRCluster
type DRClusterSpec struct {
	// CIDRs is a list of CIDR strings. An admin can use this field to indicate
	// the CIDRs that are used or could potentially be used for the nodes in
	// this managed cluster.  These will be used for the cluster fencing
	// operation for sync/Metro DR.
	CIDRs []string `json:"cidrs,omitempty"`

	// ClusterFence is a string that determines the desired fencing state of the cluster.
	ClusterFence ClusterFenceState `json:"clusterFence,omitempty"`

	// Region of a managed cluster determines it DR group.
	// All managed clusters in a region are considered to be in a sync group.
	Region Region `json:"region,omitempty"`

	// S3 profile name (in Ramen config) to use as a source to restore PV
	// related cluster state during recovery or relocate actions of applications
	// to this managed cluster;  hence, this S3 profile should be available to
	// successfully move the workload to this managed cluster.  For applications
	// that are active on this managed cluster, their PV related cluster state
	// is stored to S3 profiles of all other drclusters in the same
	// DRPolicy to enable recovery or relocate actions to those managed clusters.
	S3ProfileName string `json:"s3ProfileName"`
}
```
DR Cluster Controller的作用有：
1. 根据`ramenConfig.DrClusterOperator.DeploymentAutomationEnabled`配置，在受管集群上自动安装 DR Cluster controller和volsync Operator。并在hub cluster中创建`ramen-dr-cluster-operator-config`，内容与`ramen-dr-hub-operator-config`一致
2. 验证DRCluster中的CIDR格式
3. 通过创建或者修改Managed Cluster上的NetworkFence资源处理Fencing。
  - 2.1 `Spec.ClusterFence = Unfenced`
  - 2.2 `Spec.ClusterFence = ManuallyFenced`
  - 2.3 `Spec.ClusterFence = ManuallyUnfenced`
  - 2.4 `Spec.ClusterFence = Fenced`
4. 如果`DRCluster`资源被删除，则：
  - 3.1 检查是否有DR Policy正在使用该DRCluster，如果有，则删除失败。
  - 3.2 如果没有，则先删除名为`ramen-dr-cluster`的MW。
  - 3.3 如果`Spec.ClusterFence == Fenced ｜ Unfenced`，则还需要清理NetworkFence。
5. 验证DRCluster中的s3profile是否可以建立连接。

### DR Placement Controller
```
type DRPlacementControlSpec struct {
	// PlacementRef is the reference to the PlacementRule used by DRPC
	PlacementRef v1.ObjectReference `json:"placementRef"`

	// DRPolicyRef is the reference to the DRPolicy participating in the DR replication for this DRPC
	DRPolicyRef v1.ObjectReference `json:"drPolicyRef"`

	// PreferredCluster is the cluster name that the user preferred to run the application on
	PreferredCluster string `json:"preferredCluster,omitempty"`

	// FailoverCluster is the cluster name that the user wants to failover the application to.
	// If not sepcified, then the DRPC will select the surviving cluster from the DRPolicy
	FailoverCluster string `json:"failoverCluster,omitempty"`

	// Label selector to identify all the PVCs that need DR protection.
	// This selector is assumed to be the same for all subscriptions that
	// need DR protection. It will be passed in to the VRG when it is created
	PVCSelector metav1.LabelSelector `json:"pvcSelector"`

	// Action is either Failover or Relocate operation
	Action DRAction `json:"action,omitempty"`
}
```

DR Placement Controller的作用有：
1. Watch DRPC 资源，触发reconcile
2. Watch 具有annotation `drplacementcontrol.ramendr.openshift.io/drpc-name` 和 `drplacementcontrol.ramendr.openshift.io/drpc-namespace` 的PlacementRule的变化，并触发reconcile。
3.  Watch 具有annotation `drplacementcontrol.ramendr.openshift.io/drpc-name` 和 `drplacementcontrol.ramendr.openshift.io/drpc-namespace` 的ManifestWork的变化，并触发reconcile。
4. Watch 具有annotation `drplacementcontrol.ramendr.openshift.io/drpc-name` 和 `drplacementcontrol.ramendr.openshift.io/drpc-namespace` 的ManagedClusterView的变化，并触发reconcile。
5. 从Spec.PlacementRef中获取User Placement Rule，placement rule 应该包含1个cluster replica并且scheduler是ramen，并且添加annotation  `drplacementcontrol.ramendr.openshift.io/drpc-name` 和 `drplacementcontrol.ramendr.openshift.io/drpc-namespace`。
6. 如果DR Placement Control 或者其依赖的placemenrule 需要被删除
  - 则该DRPC也需要被删除，并移除从DRPC和placementRule上移除`drpc.ramendr.openshift.io/finalizer`
  - ？？？？？？
7. 从Spec.DRPolicyRef中获取DR Policy，为DR Policy设置label `cluster.open-cluster-management.io/backup: resource`和`drpc.ramendr.openshift.io/finalizer`
8. 为placemenrule设置`drpc.ramendr.openshift.io/finalizer`
9. 验证DR Policy的状态，必须包含`Validated`为true的condition。
10. 获取DR Policy包含的clusters，并获取相应的DR Cluster资源。
11. 如果PreferredCluster为空，则clone一个名为`drpc-plrule-<drpc-name>-<drpc-namepsace>`的User Placement Rule，并填入DRPolicy中的clusters。并reconcile等待该Clone的drpc生成Decisions。
12. 在cluster namespace创建一个带有annotation`drplacementcontrol.ramendr.openshift.io/drpc-name` 和`drplacementcontrol.ramendr.openshift.io/drpc-namespace`的managedClusterview，获取managed cluster中application namespace中和drpc同名的vrg
13. 如果policy是metrodr的，则disable volsync。
14. 保存DRPC的当前状态。
15. 根据Spec.Action执行：
  - 4.1 其他：
    - 先从PreferredCluster获取home cluster，如果没有则从clone的User Placement Rule获取home cluster
    - 检查vrg是否已经在home cluster上部署了，如果没有部署则找到当前部署vrg的cluster，并更新到drpc的status中返回。
	- 在home cluster上创建带有annotation`drplacementcontrol.ramendr.openshift.io/drpc-name` 和`drplacementcontrol.ramendr.openshift.io/drpc-namespace`的primary的VRG MW，如果DR policy支持Metro则设置sync，并disable volsync。如果支持Regional则设置Async，VGR的PVCSelector设置为spec.PVCSelector
    - 更新User Placement Rule的decision为home cluster
    - 部署volsync的配置。（TODO）
    - 更新DRPC Status.PreferredDecision为home cluster
  - 4.2 Failover
    - 如果 failoverCluster 为空, 则失败并返回
    - 如果已经执行了failed over, 则清理环境
    - 设置preferredCluster的VRG为secondary
    - 更新UserPlacementRule decision 为 failoverCluster
    - 为failoverCluster创建VRG并设置为Primary
    - 更新 DRPC 的状态
    - 一旦preferredCluster中的VRG状态更改为Secondary，则删除该VRG的MW
  - 4.3 Relocate

## DR Cluster

### Protected Volume Replication Group List Controller

该Controller是Ramen最近新加的一个feature，其主要作用就是从S3上将

### Volume Replication Group Controller

VRG(VolumeReplicationGroup)用于管理一组需要复制的 PVC。它是一个命名空间级别的资源，负责确保以下内容：
- 对于每个现有的或动态创建的 PVC：
  - 确保 PVC 在复制之前不会被删除
  - 确保 PVC 在复制之前已被绑定
  - 确保在Reconciling的时候仅保护还未被删除的 PVC
  - 确保绑定到 PVC 的 PV 在受保护期间不会被删除
  - 将 PV 集群数据备份到外部 S3 存储，以便在远程的集群上恢复它们
- 为需要保护的 PVC 创建和管理 VolumeReplication 资源
- 通过确保 VR 达到相同的状态，管理 VRG 中的状态变化。Coordinating PVC 状态并确保：
  - 标记为Secondary时，PVC应该未使用
  - 标记为Secondary时，PVC 被标记为删除
- 删除VRG之前，确保 VR 处于所需状态。

### VRG CRD
```
apiVersion: ramendr.openshift.io/v1alpha1
kind: VolumeReplicationGroup
metadata:
  name: vrg-sample
  generation: <generation>
spec:
  pvcSelector:
    matchLabels:
      <key>: <value>
  volumeReplicationClass: <string>
  replicationState: "Primary"|"Secondary"
  s3Endpoint: <url-string>
  s3SecretName: <string>
```

- PVCSelector: 用于标识属于此 VRG 且需要复制的所有 PVC
- VolumeReplicationClass: 此replication group中所有卷的 ReplicationClass；此值会赋值到创建的 VolumeReplication CR
- ReplicationState: 此复制组中所有卷 [主要或次要] 的目标状态；此值会赋值到创建的 VolumeReplication CR
- S3Profiles: 用于复制 PV 集群数据的 S3 配置文件

```
status:
  protectedPVCs: [
    pvcName: <string>
    conditions: [
      type: ["Available"]
      status: [true|false|unknown]
      observedGeneration: <generation>
      lastTransitionTime: <time>
      reason: "Error"|"Progressing"|"Replicating"
      message: <human readable string>
    ]
  ]
  conditions: [
    type: ["Available"]
    status: [true|false|unknown]
    observedGeneration: <generation>
    lastTransitionTime: <time>
    reason: ["Replicating"|"Progressing"|"Error"]
    message: <human readable string>
  ]
```
- status.conditions:
  - type: "Available" 用于表示 VRG resource的状态。
  - status
    - "Unknown" VRG还没有开始reconciliation
    - "True": VGR完成reconciliation
      - reason 变为 "Replicating"
    - "False" VRG还在reconciliation或者发生错误
      - reason 变为Progressing|Error
- status.protectedPVCs:
  - pvcName: PVC的名字
  - conditions:
    - type "Available" 表示有效的 PVC protection
    - status
      - "True" if reason is "Replicating"
      - "False" if reason is one of "Error" or "Progressing", to denote any hard errors or that reconciliation is in progress

### VRG reconciliation

#### PVC preparation and protection for all states
在继续进行状态更改之前，所有协调状态更改都需要确保 PVC 处于正确的状态并受到保护。采取以下步骤来确保相同：
- 检查 PVC 是否已被处理，检查 PVC 上是否已存在`vr-protected`注释
- 如果 PVC 未绑定，则继续下一个 PVC，但重新requeue reconciliation
  - 应该绑定 PVC，以复制绑定的PV
- 检查是否未在 PVC 上设置 pvc-vr-protection finalizer以及PVC是否正在被删除：
  - 如果正在被删除，则跳过当前 PVC 继续下一个 PVC。可以跳过正在删除但尚未受保护的 PVC
- 将 pvc-vr-protection finalizer添加到 PVC，使VR在PVC删除之前删除。当 VRG 被删除时，VR 也会被删除。
- 将绑定 PV 的`reclaimPolicy`更改为`Retain`，如果尚未`Retain`并添加注释`vr-retained`以记住 VRG 处理所做的更改
  - 绑定的 PV 需要`Retain`，直到 PVC 被用户在`Primary`的集群上删除，这样可以确保底层存储卷在复制时在跨 DR 实例上可以保留
- 备份 Bound PV 的集群数据
- 将`vr-protected`注释添加到 PVC

#### Reconciling VRG as Primary
- 添加`vrg-protection`finalizer到 VRG 实例
- 选择所有匹配`PVCSelector`的 PVC 进行处理
- 对于每个 PVC
  - 如[上所述](#pvc-preparation-and-protection-for-all-states)准备和保护 PVC
  - [查找|创建] 该PVC的 primary VR
- 对于每个受保护的 PVC
  - 检查 VR 状态是primary，如果没有，将状态更新为progressing
- 如果每一个 PVC 都不是progressing并且没有任何执行错误，更改状态为completed，

#### Reconciling VRG as Secondary
- 添加`vrg-protection`finalizer到 VRG 实例
- 选择所有匹配`PVCSelector`的 PVC 进行处理
- 对于每个 PVC
  - 如[上所述](#pvc-preparation-and-protection-for-all-states)准备和保护 PVC
  - 确保该PVC没有被使用或者被删除，如果不满足条件则requeue该PVC
    - 使用中的 PVC 可以将更多数据转储到卷中，如果在将卷标记为`secondary`之前not ordered可能会导致数据丢失
    - PVC 也应处于已删除状态，以确保在将其标记为`secondary`之前不会无意使用
  - 更新该PVC的VR目标状态`secondary`
- 对于每个受保护的 PVC
  - 检查 VR 状态是secondary，如果没有，将状态更新为progressing
- 如果每一个 PVC 都不是progressing并且没有任何执行错误，更改状态为completed，

#### Finalizing VRG when deleted
- 检查 VRG 实例上是否有 `vrg-protection` finalizer，如果没有结束reconciliation
- 选择所有匹配`PVCSelector`的 PVC 进行处理, 对于每个 PVC
  - 如[上所述](#pvc-preparation-and-protection-for-all-states)准备和保护 PVC
  - 根据 VRG 状态，将 PVC 作为`primary`或`secondary`作为其最终状态进行协调
  - 撤消 PVC 保护：
    - 撤消 PV retention
    - 从 PVC 中移除 pvc-vr-protection finalizer
  - 为 PVC 删除 VR
- 如果每一个 PVC 都不是progressing并且没有任何执行错误，更改状态为completed，

## Summary

![Summary](../../../assets/images/posts/odr.drawio.png)