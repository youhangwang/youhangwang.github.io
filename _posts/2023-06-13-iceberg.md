---
title: Iceberg Overview
tags: Iceberg
---

数据是组织做出关键业务决策的主要资产。无论是分析产品年销售额的历史趋势，还是对未来机会进行预测，数据塑造了组织做出可靠选择的方向。此外，在当今时代，数据不仅是可有可无的东西，而是不仅要在市场上取胜，甚至要参与竞争的必要条件。由于对信息的需求如此之大，人们付出了巨大的努力来积累组织内各种系统生成的数据以获取洞察力。

与此同时，各种运营和分析系统生成数据的速度也猛增。虽然更多的数据为企业提供了做出更明智决策的机会，但也迫切需要一个平台来存储和分析所有这些数据，以便将其用于构建分析产品，例如商业智能 (BI)报告和机器学习模型来支持决策制定。
<!--more-->

## Iceberg 的历史演变

在数据存储和处理系统方面，关系数据库 (RDBMS) 长期以来一直是记录交易数据的标准选择。例如一家运输公司，希望维护有关客户的新预订信息。这个新预订将是关系数据库系统中的一个新行。此类信息可以支持企业的日常运营。 用于支持这些特定数据处理目的的 RDBMS 系统称为联机事务处理 (Online Transaction Processing)。 针对 OLTP 优化的 RDBMS 系统有：
- PostgreSQL
- MySQL 
- Microsoft SQL Server

这些 OLTP 系统经过设计和优化，可以非常快速地一次与一行或几行进行交互。但是，对于上面的示例，如果想了解上个季度所有新预订的平均利润，当数据量很大时，使用存储在针对 OLTP 优化过的 RDBMS 中的数据将导致严重的性能问题。假设一个公司拥有大量操作系统。这些系统产生大量数据。分析团队的目标是从这些来自不同数据源（应用程序数据库）的数据聚合并构建仪表板。OLTP 系统不能胜任该任务，因为其并不是为处理涉及大量历史记录的复杂聚合查询而设计的。这些工作负载称为联机分析处理 (Online Analytical Processing) 工作负载。为了解决这些限制，需要一种针对 OLAP 工作负载优化的不同类型的系统。

### System Designed for OLAP Workloads

为 OLAP 工作负载设计的系统由一些组件组成：

![csi-snapshot](../../../assets/images/posts/OLAP-components.png)

- Storage

    要分析来自各种来源的历史数据，需要有一个系统来存储如此大量的数据。因此，存储是我们在能够处理大型数据集分析查询的系统中需要的第一个组件。有一些存储选项，例  如直接附加存储 (DAS) 上的本地文件系统、一组节点上的分布式文件系统，可以像 Hadoop 分布式文件系统 (HDFS) 一样操作，或者Amazon Simple Storage    Service (S3) 等云提供商提供的服务。
    
    关于存储类型，可以以使用面向行的或者列的数据库。近年来，面向列的数据库的采用率很高，因为事实证明它们在处理大量数据时效率更高。

- File Format

    File Format 负责以特定格式组织原始数据，然后将其存储在存储系统中。文件格式的选择会影响文件压缩、数据结构和给定工作负载的性能等。

    文件格式通常分为三个高级类别：结构化，半结构化和非结构化。对于结构化和半结构化，文件格式可以是面向行的或面向列的（columnar）。面向行的文件格式将给定行的所有列存储在一起，而面向列的文件格式将给定列的所有行存储在    一起。面向行的文件格式的两个常见示例是 CSV 和 Apache Avro。列式文件格式的示例是 Apache Parquet 和 Apache ORC。

    根据使用场景，某些文件格式可能更有利。例如，一次处理少量记录时，面向行的文件格式通常更好。相比之下，如果您一次处理大量记录，面向列的文件格式通常会更好。

- Table Format

    表格式是系统的另一个关键组件，它可以通过对大量数据的聚合查询来支持分析工作负载。表格式在上述文件格式之上扮演元数据层的角色，并负责指定数据文件应如何在存储  中布局。

    表格式的最终​​目标是抽象物理数据结构的复杂性并促进诸如执行数据操作语言 (DML) 操作（例如，执行插入、更新、删除）和更改表架构(schema)的能力。表格式还带来 了对数据安全执行 DML 操作所需的原子性和一致性保证。

- Storage Engine

    存储引擎是负责实际按照表格式指定的形式布置数据并使所有文件和数据结构与新数据保持同步的系统。存储引擎处理一些关键任务，例如数据的物理优化、索引维护和删除旧数据。

- Compute Engine

    计算引擎可以有效地处理存储系统中持久保存的大量数据。计算引擎在此类系统中的作用是运行用户工作负载来处理数据。根据数据量、计算负载和工作负载类型，可以使用一  个或多个计算引擎来处理数据。在处理大型数据集和/或繁重的计算需求时，可能需要在大规模并行处理 (MPP) 中使用分布式计算引擎。基于 MPP 的计算引擎的几个示例:
    - Apache Spark
    - Snowflake 
    - Dremio

- Catalog

    在处理不同来源的大规模的数据时，快速识别分析可能需要的数据非常重要。目录的作用是通过利用元数据来识别数据集来解决这个问题。目录是引擎和用户可以找到有关表是否存在以及每个表的其他信息（例如表名、schema以及该表的数据在存储系统中的存储位置）的中心位置。有些目录是系统内部的，只能通过该系统的引擎直接交互，例如 Postgres 和 Snowflake，而有些目录是开放给任何系统使用的，例如 Hive 和 Project Nessie。

### Data Warehouse

数据仓库 (Data Warehouse) 或 OLAP 数据库是一个集中式存储库，支持存储从操作系统、应用程序数据库和日志等各种来源获取的大量数据。

![Datawarehouse](../../../assets/images/posts/Datawarehouse.png)

数据仓库在单个系统中的拥有所有技术组件。因此，存储在 DW 系统中的所有数据都以 DW 专有的表格式以 DW 的专有文件格式存储在 DW 的存储中。然后，这些数据注册在 DW 的目录中，由 DW 的存储引擎专门管理，并且用户或分析引擎只能通过 DW 的计算引擎访问。

直到 2015 年左右，大多数 DW 的存储和计算组件都在同一节点上紧密耦合在一起，因为大多数 DW 都是在本地设计和运行的。然而，这导致了很多问题。由于数据集的体积增长越来越快，工作负载的数量和强度（即在仓库上运行的计算任务）也越来越快，扩展成为一个大问题。具体来说，没有办法根据任务独立地增加计算和存储资源。如果存储需求增长速度快于计算需求增长速度，那也没办法——即使不需要额外的计算资源，仍然需要为它付费。

这导致了下一代数据仓库的构建，重点放在了云上。下一代数据仓库于 2015 年左右作为云原生构建，允许将这两个组件分开并根据任务需要扩展计算和存储资源，甚至可以在不需要时关闭计算而不会丢失存储空间。

#### Data Warehouse的优缺点

尽管数据仓库，无论是本地还是基于云，都可以让企业轻松快速地理解所有历史数据，但在某些领域，仓库仍然会导致问题。我们在下表中列出了数据仓库的优缺点。

| Pros                                                               | Cons                                                                           |
| ------------------------------------------------------------------ | ------------------------------------------------------------------------------ |
| 数据仓库作为唯一的真实来源，因为它允许存储和查询来自不同来源的数据 | 仓库中的数据被锁定在只有仓库的计算引擎才能使用的供应商特定系统中，从而锁定数据 |
| 支持查询海量历史数据，使分析工作负载快速运行                       | 在存储和计算方面都很昂贵。随着工作量的增加，成本变得难以管理                   |
| 提供有效的数据治理策略，以确保数据可用、可用并符合安全策略         | 主要支持结构化数据                                                             |
| 组织数据，确保它针对查询进行了优化                                 | 组织无法在数据仓库中本地运行高级分析工作负载，例如机器学习                     |
| 确保写入表的数据符合technical schema                               |                                                                                |

数据仓库充当组织的集中存储库，用于存储多个来源的所有数据，使数据消费者（例如分析师和 BI 工程师）可以轻松快速地从单一来源访问数据以开始他们的分析。此外，支持数据仓库的技术组件提供可以访问大量数据的能力，同时支持在其上运行BI等工作负载。

尽管数据仓库在数据民主化中发挥了重要作用，并允许企业从各种数据源中获取历史洞察力，但它主要限于关系型工作负载。例如，回到之前的运输公司示例并假设现在想要深入了解下一季度的总销售额。在这种情况下，将需要使用历史数据构建预测模型。但是，无法通过数据仓库在本地实现此功能，因为计算引擎和其他技术组件不是为基于机器学习的任务而设计的。因此，唯一可行的选择是将数据从仓库移动或导出到支持它的其他平台。这意味着将拥有多个副本的数据，这可能会导致数据漂移、模型衰减等关键问题。

在数据仓库之上运行高级分析工作负载的另一个障碍是它只支持结构化数据。但是半结构化和非结构化数据（JSON、图像、文本等），可以使机器学习模型带来有趣的见解。对于之前的示例，可能是了解上个季度所有新预订评论的情绪。这最终会影响组织做出面向未来的决策的能力。

数据仓库中还存在特定的设计挑战。例如所有六个技术组件都紧密耦合在一个数据仓库中。在理解这之前，需要注意的一件重要事情是文件格式和表格式都是特定数据仓库的内部格式。这种设计模式导致数据架构的封闭形式。这意味着只能使用数据仓库的计算引擎访问实际数据，该引擎专门设计用于与仓库的表和文件格式进行交互。这种类型的架构让组织非常担心锁定数据。随着工作负载的增加以及随着时间的推移，大量数据被引入仓库，将被绑定到该特定平台。这意味着分析工作负载（例如 BI 和计划加入的任何未来工具）必须仅在该特定数据仓库之上专门运行。这也可以会阻止迁移到另一个可以满足要求的数据平台。

此外，一个重要的成本因素与在数据仓库中存储数据和使用计算引擎处理该数据有关。随着环境中工作负载数量的增加，此成本会随着时间的推移而增加，从而调用更多的计算资源。除了金钱成本之外，还有额外的开销，例如需要工程团队构建和管理大量 ETL（提取、转换、加载）管道以从操作系统移动数据。这些挑战促使组织寻求替代数据平台，使数据在他们的控制范围内并以开放文件格式存储，从而允许 BI 和机器学习等下游应用程序以大大降低的成本并行运行。这导致了Data Lake的出现。

### Data Lake

虽然数据仓库提供了一种对结构化数据进行分析的机制，但它仍然存在几个问题，需要不同的解决方案：
- 数据仓库只能存储结构化数据
- 数据仓库中的存储通常比本地 Hadoop 集群或云对象存储更昂贵。

为了解决这些问题，我们的目标是拥有一种更便宜且可以存储我们所有数据的替代存储解决方案。这就是所谓的数据湖。最初，使用 Hadoop 来允许使用廉价计算机集群来存储大量结构化和非结构化数据。但是仅仅能够存储所有这些数据是不够的。还需要对其进行分析。

Hadoop 生态系统包括 MapReduce，这是一个分析框架，可以从中用 Java 编写分析作业并在集群上运行它们。许多分析师更喜欢编写 SQL 而不是 Java，因此创建了 Hive 来将 SQL 语句转换为 MapReduce 作业。要编写 SQL，需要一种机制来区分存储中的哪些文件是我们要对其运行 SQL 的数据集或表的一部分。这导致了 Hive 表格式的诞生，它将一个目录和其中的文件识别为一个表。

随着时间的推移。人们从使用 Hadoop 集群转向使用云对象存储，因为它更易于管理且使用成本更低。 MapReduce 也不再受到其他分布式查询引擎的青睐，例如 Apache Spark、Presto 和 Dremio。坚持下来的是 Hive 表格式，它成为用于将存储中的文件识别为可以运行分析的单一表的标准。

与数据仓库相比，数据湖的一个显着特征是能够针对不同的工作负载利用不同的计算引擎。这很重要，因为从来没有一个计算引擎能适合每种工作负载。这只是计算本质所固有的，因为总是存在权衡，而决定权衡的内容决定了给定系统适合什么以及不适合什么。

请注意，在数据湖中，实际上并没有任何服务能够满足存储引擎功能的需求。通常，计算引擎决定如何写入数据，然后通常不会重新访问和优化数据，除非重写整个表或分区，这通常是临时完成的。

![Datalake](../../../assets/images/posts/Datalake.png)

#### Data Lake 的优缺点


没有架构模式是完美的, 对于data lake也是一样。虽然数据湖有很多好处，比如降低成本、以开放格式存储和处理非结构化数据的能力；数据湖也有一些缺点，例如性能问题、缺乏 ACID 保证和大量配置。
|Pro|Con|
|-|-| 
|Low Cost: 在数据湖上存储数据和执行查询的成本比在数据仓库中低得多。这使得数据湖对于支持对优先级不够高的数据进行分析特别有用|Performance: 由于数据湖的每个组件都是解耦的，因此不存在紧密耦合系统中存在的许多优化。这使得数据湖不适合性能和时间至关重要的高优先级数据分析。|
|Store Data in Open Formats: 在数据湖中，可以以任何文件格式存储数据，这与数据仓库不同，在数据仓库中，对数据的存储方式没有任何发言权，这通常是为该特定数据仓库构建的专有格式。这可以更好地控制数据，并在更多支持这些开放格式的工具中使用数据。|Lots of Configuration: 如前所述，将所选组件与数据仓库的优化级别进行更紧密的耦合需要大量工程。这将导致需要大量数据工程师来配置所有这些工具，这也可能是昂贵的。|
|Handle Unstructured Data: 数据仓库无法处理非结构化数据，因此如果对非结构化数据进行分析，数据湖是唯一的选择。|Lack of ACID Guarantees|

### Data Lake or Data Warehouse?

虽然数据湖提供了一个存放所有结构化和非结构化数据的好地方，但仍然存在不完善之处。在运行 ETL 将数据放入数据湖后，如果运行分析，则可以从如下两种方式中选择一个：

- 一部分数据进入数据仓库

    设置一个额外的 ETL 管道来创建用于高优先级分析的精选数据子集的副本，并将其存储在仓库中以获得数据仓库的性能和灵活性。但这会导致几个问题：
    - 额外 ETL 工作的额外计算成本，以及数据副本的成本。
    - 可能需要额外的数据副本来填充不同业务线，甚至需要更多副本，因为分析师以 BI 提取的形式创建数据子集的物理副本以加速dashboards。导致难以管理、跟踪和保持同步的数据副本网络。

- 直接在数据湖上运行分析

    使用支持数据湖工作负载（如 Dremio、Presto、Apache Spark、Trino、Apache Impala 等）的查询引擎来对数据湖执行查询。这些引擎通常非常适合只读工作负载。然而，由于 Hive 表格式的限制，他们在尝试从数据湖中安全地更新数据时遇到了复杂的问题。

所以数据湖和数据仓库各有其独特的优点和缺点。开发一种新的架构，将所有这些好处结合在一起，同时最大限度地减少它们的所有错误，这将对我们有利，这种架构称为data lakehouse。

### Data lakehouse

虽然数据仓库具有性能和易用性方面的优点，但数据湖也具有降低成本，并减少了复杂的数据复制网络中的数据漂移。使Data lakehouse真正独一无二的是data lake table formats，它消除了之前 Hive 表格式的所有问题。数据存储在与数据湖相同的位置，使用与数据湖一样的查询引擎，数据以与数据湖相同的格式存储，真正将世界从一个`只读`数据转变到一个`数据世界的中心` Data lakehouse 的是表格格式。当直接在数据湖存储上处理数据时，表格式可实现更好的一致性、性能和 ACID 保证。

- 更少的副本，更少的漂移

    有了 ACID 保证和更好的性能，就不必将数据移动到 lakehouse，这可以拥有一个副本更少的更精简的架构。更少的副本意味着更少的存储成本、更少的将数据移动到数据仓库的计算成本，以及更好的数据管理以保持对法规和内部控制的合规性。

- 更快的查询，更快的洞察力

    最终目标始终是从我们数据的质量洞察中获得商业价值，其他一切都只是实现这一目标的步骤。如果您可以获得更快的查询，则意味着您可以更快地获得见解。 Data Lakehouses 通过在查询引擎、表格式和文件格式上使用优化来实现更快的查询执行。

- 错误不会导致不可挽回的损失

    Data Lakehouse 表格式可以通过使用快照隔离来撤销错误，从而允许您将表恢复到之前的快照。

- 负担得起的架构是商业价值

    增加利润有两种办法：增加收入和降低成本。Data lakehouse不仅可以帮助您获得业务洞察力来增加收入，还可以帮助您降低成本。通过避免数据重复来降低存储成本，避免因额外的 ETL 工作来移动数据而产生的额外计算成本，并享受与典型数据仓库费率相比更低的存储和计算价格。

- 开放架构，安心

    Data Lakehouses 建立在开放格式之上，例如作为表格格式的 Apache Iceberg 和作为文件格式的 Apache Parquet。许多工具都可以读取和写入这些格式，这使您可以避免与供应商锁定导致成本增加，并防止工具锁定。

![Datalake](../../../assets/images/posts/datalakehouse.png)

## Table Format

表格式是一种构建数据集文件并将它们呈现为统一`表格`的方法。从用户的角度来看，它可以定义为`这个表中有什么数据？`这个问题的答案。

这个简单的答案可以使多个个人、团队和工具能够同时与表中的数据进行交互，无论他们是从表中读取还是向表中写入数据。表格格式的主要目的是为用户和工具提供表格的抽象，使他们更容易以有效的方式与底层数据进行交互。

自关系数据库管理系统 (RDBMS)（例如 System R、Multics 和 Oracle）问世以来，表格式就一直存在，它们首先实现了 Edgar Codd 的关系模型，尽管当时并未使用术语`表格式`。在这些系统中，用户可以将一组数据称为表，数据库引擎负责以文件的形式管理数据集在磁盘上的字节布局，同时还处理事务等复杂性。

与这些 RDBMS 中数据的所有交互，例如读取和写入，都由数据库的存储引擎管理。没有其他引擎可以在不冒系统损坏风险的情况下直接与文件交互。数据如何存储的细节被抽象出来，用户理所当然地认为平台知道特定表的数据位于何处以及如何访问它。

然而，在当今的大数据世界中，依靠单一的封闭引擎来管理对底层数据的所有访问已不再实用，因为传统的 RDBMS 已不再足够。

在数据湖中，所有数据都作为文件存储在某些存储解决方案（例如，Amazon S3、Azure 的 ADLS、Google 的 GCS）中，因此单个表可能由该存储上的数十个、数百个甚至数千个单独的文件组成。 在将 SQL 与我们最喜欢的分析工具一起使用或使用 Java、Scala、Python 和 Rust 等语言编写临时脚本时，我们不想不断定义这些文件中哪些文件在表中，哪些文件不在表中。这不仅会很乏味，而且还可能导致数据的不同用途之间的不一致。

因此，解决方案是为数据湖创建一种理解`此表中有哪些数据`的标准方法。

![table](../../../assets/images/posts/table.png)

### 早期的Table Format

当谈到在 Hadoop 数据湖上运行分析时，使用了 MapReduce 框架，这需要用户编写复杂而乏味的 Java 作业，而这对许多分析师来说是无法访问的。感受到这种情况的痛苦的 Facebook 在 2009 年开发了一个名为 Hive 的框架。Hive 提供了一个关键优势，可以使 Hadoop 上的分析变得更加容易，即能够直接编写 SQL 而不是 MapReduce 作业。

Hive 框架将采用 SQL 语句，然后将它们转换为可以执行的 MapReduce 作业。为了编写 SQL 语句，必须有一种机制来理解 Hadoop 存储上的哪些数据代表一个唯一的表，Hive 表格式和用于跟踪这些表的 Hive Metastore 诞生了。

#### Hive表结构

Hive 表格式采用将表定义为指定目录中的所有文件的方法，这些表的分区将是子目录。这些定义表的目录路径由称为 Hive Metastroe的服务跟踪，查询引擎可以访问该服务以了解在哪里可以找到适用于其查询的数据。

![hivetable](../../../assets/images/posts/hivetable.png)

Hive 表格式有几个好处：
- 它启用了比全表扫描更高效的查询模式，分区和分桶等技术可以避免扫描每个文件以获得更快的查询
- 它与文件格式无关，因此它允许数据社区超时开发更好的文件格式，如 Apache Parquet，并在 Hive 表中使用它们，并且在使数据在 Hive 表中可用之前不需要转换（例如 Avro、CSV/TSV ).
- 通过metastore中列出的目录的原子交换，可以对表中的单个分区进行原子更改。
- 随着时间的推移，这成为大多数数据工具的实际标准，并为`这张表中有什么数据？`提供统一的答案。

虽然这些好处很重要，但随着时间的推移，许多限制也变得显而易见：
- 文件级更改效率低下，因为没有像 Hive Metastore 可用于交换分区目录的相同方式原子交换文件的机制。您基本上只能在分区级别进行交换以自动更新单个文件。
- 虽然可以原子地交换一个分区，但没有一种机制可以将多个分区作为一个事务来原子地更新。
- 确实没有很好的机制来启用并发同步更新，尤其是使用 Hive 本身以外的工具时。
- 列出文件和目录的引擎非常耗时并且会减慢查询速度。
- 分区列通常从其他列派生而来，例如从时间戳派生出月份列。分区仅在您按分区列进行过滤时才有用，而对时间戳列进行过滤的人可能不会凭直觉知道还要对派生月份列进行过滤，从而导致全表扫描，因为没有利用分区。
- 表统计信息将通过异步作业收集，如果有任何统计信息可用，则通常会导致状态表统计信息，从而使查询引擎难以进一步优化查询。
- 由于对象存储通常会限制针对相同前缀的请求（将对象存储前缀想象成类似于文件目录），因此对单个分区中包含大量文件的表的查询（所有文件都在一个前缀中）可能有性能问题。

数据集和用例的规模越大，这些问题就会越多，从而导致需要新解决方案的巨大痛苦，因此创建了更新的表格格式。

### 现代的Table Format

为了解决 Hive 表格式的局限性，新一代的表格式应运而生，采用不同的方法来解决 Hive 的问题。

现代表格式的创建者意识到导致 Hive 表格式挑战的缺陷是表的定义是基于目录的内容，而不是基于单个数据文件。 Apache Iceberg、Apache Hudi 和 Delta Lake 等现代表格式都采用了这种将表格定义为规范文件列表的方法，为引擎提供有关哪些文件组成表格的信息的元数据，而不是哪些目录。这种定义`什么是表`的更精细的方法打开了 ACID（原子性、一致性、隔离性、持久性）事务、时间旅行等功能的大门。

#### 现代的 Table Format解决了哪些问题？
现代表格式都旨在带来一组核心的主要好处：
- 现代表格格式允许 ACID 事务，这些事务是完全完成或被取消的安全事务。在 Hive 表格式等早期格式中，许多事务无法获得这些保证。
- 当有多个编写器时启用安全事务。如果两个或更多写入者写入一个表，则有一种机制可以确保完成第二个写入的写入者知道并考虑其他写入者为保持数据一致性所做的工作。
- 更好地收集表统计信息和元数据，可以让查询引擎扫描数据以更有效地进行计划。

虽然大多数现代表格式都提供了上述内容，但 Apache Iceberg 格式提供了这些内容并解决了 Hive 表格式的许多其他问题。

## Apache Iceberg

Apache Iceberg 是 Ryan Blue 和 Daniel Weeks 于 2017 年在 Netflix 创建的一种表格式，它是出于克服 Hive 表格式在性能、一致性等方面的挑战的需要。 2018 年，该项目开源并捐赠给 Apache 软件基金会，许多其他组织开始参与该项目，包括 Apple、Dremio、AWS、腾讯、LinkedIn、Stripe 等，此后许多组织都为该项目做出了贡献。

Netflix 在创建 Apache Iceberg 格式时得出的结论是，Hive 格式的许多问题都源于一个简单但根本的缺陷。该缺陷是每个表都作为目录和子目录进行跟踪，限制了提供一致性保证、更好的并发性等所需的粒度。考虑到这一点，netflix 着手创建一种新的表格格式，并牢记几个目标：

- 一致性

    如果对表的更新发生在多个事务中，最终用户可能会遇到他们正在查看的数据不一致的情况。跨多个分区对表的更新应该快速且原子地完成，以便数据对最终用户是一致的。他们要么看到更新前的数据，要么看到更新后的数据，中间什么也看不到。

- 性能

    由于 Hive 的文件/目录列表瓶颈，查询计划在实际执行查询之前需要很长时间才能完成。表应提供元数据并避免过多的文件list，这样不仅查询计划可以更快，而且生成的计划也可以更快地执行，因为它们只扫描满足查询所需的文件。

- 便于使用

    要获得分区等技术的好处，最终用户不必了解表的物理结构。该表应该能够为用户提供基于自然直观查询的分区的好处，而不是依赖于过滤从他们已经过滤的列派生的额外分区列。

- 可进化性

    更新 Hive 表的模式可能会导致不安全的事务，更新表的分区方式会导致需要重写整个表。表应该能够安全地发展其架构和分区方案，而无需重写表。

- 可扩展性
    
    以上所有内容应该能够在 Netflix 的 PB 级数据上完成。

因此，他们开始创建 Iceberg 格式，该格式专注于将表格定义为规范的文件列表，而不是将表格跟踪为目录和子目录的列表。

Apache Iceberg 项目是一个规范，一个关于如何跨多个文件编写定义data lakehouse表的元数据的标准。为了支持采用这个标准，Apache Iceberg 有许多支持库来帮助个人使用格式或为计算引擎提供支持。除了这些库，该项目还为 Apache Spark 和 Apache Flink 等开源计算引擎创建了实现。

### Apache Iceberg 架构

Apache Iceberg 通过元数据树跟踪表的分区、排序、模式随时间变化的更多信息，引擎可以使用这些元数据树来计划查询，而所花费的时间只是 Hive 表所花时间的一小部分。

![iceberg_arch](../../../assets/images/posts/iceberg_arch.png)

此元数据树将表的元数据分解为四个部分：

- Manifest Files

    数据文件列表，包含每个数据文件的位置/路径和关于这些数据文件的关键元数据，允许创建更有效的执行计划。

- Manifest List

    定义表的单个快照的一个文件，是一个Manifest Files的list。

- 元数据文件

    定义表结构的文件，包括其模式、分区方案和快照列表。

- 目录

    与Hive Metastore一样，它跟踪表的位置，但它不包含表名称到目录集的映射，而是包含表名称到最新元数据文件位置的映射。

### Apache Iceberg 的功能

Apache Iceberg独特的架构提供了越来越多的功能，这些功能不仅解决了Hive的挑战，还为数据湖和数据湖工作负载解锁了全新的功能。

以下是Apache Iceberg的主要功能：

- ACID事务

    Apache Iceberg使用乐观并发控制等技术来启用ACID，即使事务由多个读写器处理。通过这种方式，可以在数据湖上运行要么提交成功要么失败的事务，两者之间没有任何关系。
    
    并发保证由目录处理，因为它是一种内置ACID保证的机制，这允许Iceberg表上的事务是原子的，并提供正确性保证。如果不存在原子性，两个不同的系统可能会有冲突的更新，导致数据丢失。

- 分区演进

    在Apache Iceberg之前，数据湖的一大头痛问题是需要更改表的物理优化。通常，当分区需要更改时，唯一的选择就是重写整个表，而且当规模很大时代价可能会非常大。另一种选择是只使用现有的分区方案，而牺牲更好的分区方案所能提供的性能改进。
    
    使用Apache Iceberg，可以随时更新表的分区方式，而无需重写表及其所有数据。由于分区的一切都与元数据有关，因此对表结构进行更改所需的操作既快捷又便宜。

- 隐藏分区

    有时用户不知道表是如何进行物理分区的，坦率地说，他们不应该在意。通常，一个表是由某个时间戳字段划分的，用户希望通过该字段进行查询（例如，获取过去90天的平均收入）。然而，对于用户来说，最直观的方法是包含event_timestamp>=DATE_SUB（当前日期，间隔6个月）的过滤器。然而，这将导致完整的表扫描，因为表实际上是由称为event_year、event_month和event_day的字段分区的，因为在时间戳上进行分区会产生微小的分区，因为值的粒度为秒、毫秒或更低。

    这个问题通过Apache Iceberg如何处理分区来解决。Apache Iceberg中的分区分为两部分，物理分区应该基于的列，以及对该值的可选转换，包括bucket、truncate、year、month、day和hour等函数。应用转换的能力消除了只为分区而创建新列的需要。

- 行级表操作

    表的行级更新模式可以基于两种形式优化：写入时复制（COW）或读取时合并。使用COW时，对于给定数据文件中任何行的更改，即使更新了其中的某个单个记录，也会重写整个文件（在新文件中进行行级更改）。当使用读取时合并（MOR）时，对于任何行级更新，只会写入一个新文件，该文件包含对读取时协调的受影响行的更改。这为加快繁重的更新和删除工作负载提供了灵活性。

- 时间旅行

    Apache Iceberg提供了不可变的快照，因此可以访问表的历史状态信息，从而允许对过去某个给定时间点的表的状态或通常所说的时间旅行运行查询。这可以在不需要将表的数据复制到单独的位置或复制某个时间点输出的机器学习模型的情况下进行季度末报告。

- 版本回滚

    Iceberg的快照隔离不仅允许按原样查询数据，还可以将表的当前状态恢复为以前的任何快照。因此，纠正错误就像倒退一样容易。

- Schema Evolution

    表会发生变化，无论这意味着添加/删除列、重命名列还是更改列的数据类型。不管表需要如何演变，Apache Iceberg都提供了强大的模式演变功能。