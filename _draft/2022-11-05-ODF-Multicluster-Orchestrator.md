---
title: OpenShift Data Foundation Multicluster Orchestrator
tags: ODF DR MulticlusterOrchestrator
---

ODF Multicluster Orchestrator 是 Kubernetes Operator 和 ACM addons 的组合，它们协同工作以编排分布在多个 OpenShift 集群中的 OpenShift Data Foundation 集群。它利用 Red Hat Advanced Cluster Management for Kubernetes 作为它的控制平面，还使用它的addon框架。
<!--more-->


## Operator Manager
init函数在Operator启动时添加Operator Manager：
```
func init() {
	rootCmd.AddCommand(controllers.NewManagerCommand())
}
```

```

func NewManagerCommand() *cobra.Command {
	mgrOpts := NewManagerOptions()
	cmd := &cobra.Command{
		Use:   "manager",
		Short: "Multicluster Orchestrator for ODF",
		Run: func(cmd *cobra.Command, args []string) {
			mgrOpts.runManager()
		},
	}
	mgrOpts.AddFlags(cmd)
	return cmd
}

func (o *ManagerOptions) runManager() {
	ctrl.SetLogger(zap.New(zap.UseFlagOptions(&o.ZapOpts)))
	setupLog := ctrl.Log.WithName("setup")

	mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{
		Scheme:                 mgrScheme,
		MetricsBindAddress:     o.MetricsAddr,
		Port:                   9443,
		HealthProbeBindAddress: o.ProbeAddr,
		LeaderElection:         o.EnableLeaderElection,
		LeaderElectionID:       "1d19c724.odf.openshift.io",
	})
	if err != nil {
		setupLog.Error(err, "unable to start manager")
		os.Exit(1)
	}

	namespace := os.Getenv("POD_NAMESPACE")

	if err = (&MirrorPeerReconciler{
		Client: mgr.GetClient(),
		Scheme: mgr.GetScheme(),
	}).SetupWithManager(mgr); err != nil {
		setupLog.Error(err, "unable to create controller", "controller", "MirrorPeer")
		os.Exit(1)
	}
	//+kubebuilder:scaffold:builder

	if err = (&MirrorPeerSecretReconciler{
		Client: mgr.GetClient(),
		Scheme: mgr.GetScheme(),
	}).SetupWithManager(mgr); err != nil {
		setupLog.Error(err, "unable to create controller", "controller", "MirrorPeer")
		os.Exit(1)
	}

	if err := mgr.Add(manager.RunnableFunc(func(ctx context.Context) error {
		err = console.InitConsole(ctx, mgr.GetClient(), o.MulticlusterConsolePort, namespace)
		if err != nil {
			setupLog.Error(err, "unable to initialize multicluster console to manager")
			return err
		}
		return nil
	})); err != nil {
		setupLog.Error(err, "unable to add multicluster console to manager")
		os.Exit(1)
	}

	if err := mgr.AddHealthzCheck("healthz", healthz.Ping); err != nil {
		setupLog.Error(err, "unable to set up health check")
		os.Exit(1)
	}
	if err := mgr.AddReadyzCheck("readyz", healthz.Ping); err != nil {
		setupLog.Error(err, "unable to set up ready check")
		os.Exit(1)
	}

	setupLog.Info("initializing token exchange addon")
	kubeClient, err := kubernetes.NewForConfig(mgr.GetConfig())
	if err != nil {
		setupLog.Error(err, "problem getting kubeclient")
	}

	controllerRef, err := events.GetControllerReferenceForCurrentPod(context.TODO(), kubeClient, namespace, nil)
	if err != nil {
		setupLog.Info("unable to get owner reference (falling back to namespace)", "error", err)
	}
	eventRecorder := events.NewKubeRecorder(kubeClient.CoreV1().Events(namespace), tokenexchange.TokenExchangeName, controllerRef)

	agentImage := os.Getenv("TOKEN_EXCHANGE_IMAGE")

	tokenExchangeAddon := tokenexchange.TokenExchangeAddon{
		KubeClient: kubeClient,
		Recorder:   eventRecorder,
		AgentImage: agentImage,
	}

	err = (&multiclusterv1alpha1.MirrorPeer{}).SetupWebhookWithManager(mgr)

	if err != nil {
		setupLog.Error(err, "unable to create webhook", "webhook", "MirrorPeer")
		os.Exit(1)
	}

	setupLog.Info("creating addon manager")
	addonMgr, err := addonmanager.New(mgr.GetConfig())
	if err != nil {
		setupLog.Error(err, "problem creating addon manager")
	}
	err = addonMgr.AddAgent(&tokenExchangeAddon)
	if err != nil {
		setupLog.Error(err, "problem adding token exchange addon to addon manager")
	}

	g, ctx := errgroup.WithContext(ctrl.SetupSignalHandler())

	setupLog.Info("starting manager")
	g.Go(func() error {
		err := mgr.Start(ctx)
		return err
	})

	setupLog.Info("starting addon manager")
	g.Go(func() error {
		err := addonMgr.Start(ctx)
		return err
	})

	if err := g.Wait(); err != nil {
		setupLog.Error(err, "received an error. exiting..")
		os.Exit(1)
	}
}
```

Manager 中主要管理如下几种Component：
- MirrorPeer Reconciler
- MirrorPeer Webhook
- MirrorPeerSecret Reconciler
- Init Multicluster Console
- TokenExchangeAddon Manager

在进入在具体代码分析之前，我们先看下MirrorPeer CRD中包含的内容：

```
apiVersion: multicluster.odf.openshift.io/v1alpha1
kind: MirrorPeer
metadata:
  name: mirror-peer-<auto-generated-suffix>
spec:
  items:
  - clusterName: <ManagedClusterName>
    storageClusterRef:
      name: ocs-storagecluster
      namespace: openshift-storage
  - ...
  manageS3: true
  schedulingIntervals:
  - <schedule list>
  type: async | sync
status:
  phase: ExchangingSecret | ExchangedSecret | S3ProfileSyncing ｜ S3ProfileSynced ｜ Deleting
```

## MirrorPeer Reconciler





## MirrorPeer Webhook

MirrorPeer Webhook 主要包含两个部分：
- Mutate Webhook
  - 检查是否设置schedulingIntervals，如果未有设置，则设置默认值`[]string{"5m"}`
- Validate Webhook
  - Create: spec.items不能为空，spec.schedulingIntervals必须被赋值，并满足格式`^\d+[mhd]$`
  - Update: spec.type不能被修改，spec.item不能被修改，spec.items不能为空，spec.schedulingIntervals必须被赋值，并满足格式`^\d+[mhd]$`
  - Delete: 不检查


## MirrorPeerSecret Reconciler

Reconcile满足如下条件的secret：

- 如果是Create事件
  - 是source secret（secret包含`multicluster.odf.openshift.io/secret-type = BLUE`的label）,或者
  - 是internal secret（secret包含`multicluster.odf.openshift.io/secret-type = INTERNAL`的label）
- 如果是Delete事件
  - 是source secret（secret包含`multicluster.odf.openshift.io/secret-type = BLUE`的label）,或者
  - 是destination secret（secret包含`multicluster.odf.openshift.io/secret-type = GREEN`的label）
- 如果是Update事件
  - 新/旧的secret同时是source secret（secret包含`multicluster.odf.openshift.io/secret-type = BLUE`的label）,或者
  - 新/旧的secret同时是destination secret（secret包含`multicluster.odf.openshift.io/secret-type = GREEN`的label）,或者
  - 新/旧的secret同时是internal secret（secret包含`multicluster.odf.openshift.io/secret-type = INTERNAL`的label）

具体的reconcile流程为：

- 如果secret是source secret，则
  - 首先验证该secret的内容，包括Data中的namespace，storage-cluster-name，secret-origin，secret-data四个Key是否存在。
  - 


## Init Multicluster Console
## tokenExchangeAddon Manager

## ACM Addon

```
func init() {
	rootCmd.AddCommand(tokenexchange.NewAgentCommand())
}
```